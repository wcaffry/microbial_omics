{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook designed to do differential analysis on LCMS results based on batch, type of sample and various other conditons.  Reads in LCMS results\n",
    "files from multiple experiements, performs various normalizations for data vizualization and exploration, and matches differential protiens with\n",
    "protein annotation for further exploration\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import functools\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from skbio import DistanceMatrix\n",
    "from skbio.tree import nj\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.stats.ordination import pcoa\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import statsmodels.formula.api as smf \n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Reading in data and annotations\"\"\"\n",
    "data_dir = '/Users/home/data/'\n",
    "genome_annotations = pd.read_csv(data_dir + 'annotations.csv')\n",
    "metadata = pd.read_excel(data_dir + 'metadata.xlsx', index_col='sample_name')\n",
    "\n",
    "\"\"\"Reading in multiple LCMS files from multiple experiments for larger comparison sets\"\"\"\n",
    "lcms_1 = pd.read_csv(data_dir + 'lcsms_file_1.csv', index_col='Accession') \n",
    "lcms_2 = pd.read_csv(data_dir + 'lcsms_file_2.csv', index_col='Accession')\n",
    "lcms_3 = pd.read_csv(data_dir + 'lcsms_file_3.csv', index_col='Accession') \n",
    "lcms_4 = pd.read_csv(data_dir + 'lcsms_file_4.csv', index_col='Accession') \n",
    "lcms_5 = pd.read_csv(data_dir + 'lcsms_file_5.csv', index_col='Accession')\n",
    "\n",
    "\"\"\"selecting LCMS files to use in below analysis\"\"\"\n",
    "lcms_files = [lcms_1, lcms_2, lcms_3, lcms_4, lcms_5,]\n",
    "\n",
    "\"\"\"Merging all files \"\"\"\n",
    "def merge_lcms(lcms_files):\n",
    "    \"\"\"get number of files\"\"\"\n",
    "    x = len(lcms_files)\n",
    "    merged_frame = pd.DataFrame(columns = [\"Accession\", \"drop\"])\n",
    "    merged_frame.set_index(\"Accession\", inplace=True)\n",
    "    for i in lcms_files:\n",
    "        temp_columns = [col for col in i.columns if \"spec\" in col]\n",
    "        temp_frame = i[temp_columns]\n",
    "        merged_frame = merged_frame.merge(temp_frame, left_index=True, right_index=True, how='outer')\n",
    "    merged_frame.drop('drop', axis=1, inplace=True)\n",
    "    return merged_frame\n",
    "    \n",
    "raw_data_df = merge_lcms(lcms_files)\n",
    "raw_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Count Normalization\"\"\"\n",
    "def normalize_lcms(raw_data_df):\n",
    "    column_counts = {}\n",
    "    norm_dict = {}\n",
    "    \"\"\"Get the column counts for each column\"\"\"\n",
    "    for column in raw_data_df.columns.tolist():\n",
    "        column_counts[column] = raw_data_df[column].sum()\n",
    "    \n",
    "    \"\"\"Get the normalization value for each column\"\"\"\n",
    "    for column in raw_data_df.columns.tolist():\n",
    "        norm_dict[column] = Series([*column_counts.values()]).mean() / column_counts[column]\n",
    "    \n",
    "    norm_df = pd.DataFrame.from_dict(norm_dict, orient='index')\n",
    "    \"\"\"Apply normalization factors, remember norm_df is a dataframe and column 0 is where the values are stored\"\"\"\n",
    "    normalized_data_df = raw_data_df.T.mul(norm_df[0], axis=0).T\n",
    "    \"\"\"Remove low counts\"\"\"\n",
    "    normalized_data_df['max'] = normalized_data_df.max(axis=1)\n",
    "    normalized_data_df = normalized_data_df[normalized_data_df['max'] > 2]\n",
    "    normalized_data_df.drop('max', axis=1, inplace=True)\n",
    "    normalized_data_df.fillna(0, inplace=True)\n",
    "    return normalized_data_df\n",
    "\n",
    "normed_df = normalize_lcms(raw_data)\n",
    "normed_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Quantile Normalization\"\"\"\n",
    "def quantile_normalize(df):\n",
    "    df_sorted = pd.DataFrame(np.sort(df.values,\n",
    "                                     axis=0), \n",
    "                             index=df.index, \n",
    "                             columns=df.columns)\n",
    "    df_mean = df_sorted.mean(axis=1)\n",
    "    df_mean.index = np.arange(1, len(df_mean) + 1)\n",
    "    df_qn =df.rank(method=\"min\").stack().astype(int).map(df_mean).unstack()\n",
    "    return(df_qn)\n",
    "quant_normed = quantile_normalize(raw_data)\n",
    "quant_normed.fillna(0, inplace=True)\n",
    "quant_normed.head(2)\n",
    "quant_normed.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Removing short hypothetical proteins from the data, as they are likely part of larger unknown proteins that remain unidentified\n",
    "Returns raw data for DESeq, count normalized and quantile normalized frames filtered for short proteins\"\"\"\n",
    "def length_filter(raw_df, annotations_df, normalized_df, quant_df):\n",
    "    \"\"\"get lenght df\"\"\"\n",
    "    lenght_df = annotations_df[['locus_tag', 'aa_seq']]\n",
    "    lenght_df['length'] = lenght_df['aa_seq'].str.len()\n",
    "    lenght_df.set_index(['locus_tag'], inplace=True)\n",
    "    \n",
    "    \"\"\"get length filtered indicies\"\"\"\n",
    "    short_indicies = set(set(lenght_df[lenght_df['length'] < 100].index.tolist()) & \n",
    "                        set(raw_df.index.tolist()))\n",
    "    long_idicies = set(set(lenght_df[lenght_df['length'] > 100].index.tolist()) & \n",
    "                      set(raw_df.index.tolist()))\n",
    "    \n",
    "    \"\"\"Filter for long indicies\"\"\"\n",
    "    filtered_df = raw_df.loc[long_idicies].copy()\n",
    "    filtered_df.fillna(0, inplace=True)\n",
    "    \n",
    "    \"\"\"get normalized filtered\"\"\"\n",
    "    norm_filtered = normalized_df.loc[set(set(normalized_df.index.tolist()) & set(filtered_df.index.tolist()))]\n",
    "    quant_filtered = quant_df.loc[set(set(quant_df.index.tolist()) & set(filtered_df.index.tolist()))]\n",
    "    return filtered_df, norm_filtered, quant_filtered\n",
    "\n",
    "deseq_data, norm_filtered, quant_filtered = length_filter(subset_data, es894_annotations, normed_df, quant_normed)\n",
    "\n",
    "\"\"\"Making transposed DF here for ease of use\"\"\"\n",
    "transposed = norm_filtered.T.merge(metadata, left_index=True, right_index=True)\n",
    "transposed_quant = quant_filtered.T.merge(metadata, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Looking at coefficient of variation plots as quick check of quality\"\"\"\n",
    "def coefficient_var_plot(raw_data, metadata):\n",
    "    sns.set(style='darkgrid', context='talk')\n",
    "    plotting_frame = raw_data.T.merge(metadata[['batch']], left_index=True, right_index=True, how='left')\n",
    "    groups = plotting_frame['batch'].unique().tolist()\n",
    "    print(groups)\n",
    "    for i in groups:\n",
    "        sample_plot = plotting_frame[plotting_frame['batch'] == i]\n",
    "        sample_plot.drop(['batch'], axis=1, inplace=True)\n",
    "        sample_plot = sample_plot.T\n",
    "        \n",
    "        sample_plot['mean'] = sample_plot.mean(axis=1)\n",
    "#         print(sample_df.head())\n",
    "        sample_plot['cv'] = stats.variation(sample_plot.drop('mean', axis=1), axis=1)\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sns.regplot(x=sample_plot['mean'], y=sample_plot['cv'], lowess=True, \n",
    "                    scatter_kws={\"color\": \"black\", \"s\":40, \"linewidth\":.5}, line_kws={\"color\": \"blue\", \"linewidth\":2},\n",
    "                    marker='x' )\n",
    "        ax.set_ylim(-0.1, 2)\n",
    "        ax.set_xlim(-10, 400)\n",
    "        ax.set_title(str(i + ' Coefficient of Variation'))\n",
    "        ax.set_xlabel('Protein Spectral Counts')\n",
    "        ax.set_ylabel('CV')\n",
    "        \n",
    "coefficient_var_plot(deseq_data, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DESeq2 FUNCTIONS\"\"\"\n",
    "\"\"\"Necessary to run DESeq2 before running the variance stabilizing transformation\"\"\"\n",
    "def run_deseq_in_python(counts_frame, sample_frame, exp_design):\n",
    "    \"\"\"Importing rpy2 functions\"\"\"\n",
    "    from rpy2 import robjects\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri, Formula\n",
    "    robjects.numpy2ri.activate()\n",
    "    pandas2ri.activate()\n",
    "    deseq = importr('DESeq2')\n",
    "    \n",
    "    \"\"\"Creating R dfs\"\"\"\n",
    "    count_matrix = robjects.DataFrame(counts_frame)\n",
    "    sample_matrix = robjects.DataFrame(sample_frame)\n",
    "    \n",
    "    \"\"\"Running DESeq\"\"\"\n",
    "    design = Formula(exp_design)\n",
    "    ddsFullCountTable = deseq.DESeqDataSetFromMatrix(countData = count_matrix, colData = sample_matrix, design = design)\n",
    "    dds = deseq.DESeq(ddsFullCountTable)\n",
    "    \n",
    "    \"\"\"Getting comparisons\"\"\"\n",
    "    contrasts = deseq.resultsNames(dds).copy().tolist()\n",
    "    contrasts.remove('Intercept')\n",
    "    \n",
    "    return(dds, contrasts)\n",
    "   \n",
    "def get_deseq_results(dds, contrasts):\n",
    "    \"\"\"Import and Helper functions\"\"\"\n",
    "    from rpy2 import robjects\n",
    "    from rpy2.robjects.packages import importr\n",
    "    deseq = importr('DESeq2')\n",
    "    to_dataframe = robjects.r('function(x) data.frame(x)')\n",
    "    \"\"\"Building dictionaries of dfs\"\"\"\n",
    "    fold_change_dict = {}\n",
    "    sig_fc_dict = {}\n",
    "    for i in contrasts:\n",
    "        res = deseq.results(dds, contrast = [i])\n",
    "        fold_change_dict[i] = to_dataframe(res)\n",
    "        sig_fc_dict[i] = fold_change_dict[i][fold_change_dict[i]['padj'] < 0.05].copy()\n",
    "        \n",
    "    return fold_change_dict, sig_fc_dict\n",
    "\n",
    "\"\"\"Runs DESeq on whole frame\"\"\"\n",
    "dds, contrasts = run_deseq_in_python(deseq_data, metadata, \n",
    "                                     \"~ cond_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"RUNNING DESeq NORMALIZATION\"\"\"\n",
    "\"\"\"In cell below, nothing can come before the %%R line, or be on the line with it other than the inputs.  Comments even on the \n",
    "line below seemed to be causing problems\"\"\"\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i dds -o v\n",
    "\n",
    "library('DESeq2')\n",
    "vsd = varianceStabilizingTransformation(dds)\n",
    "v = assay(vsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRANSLATING BACK INTO PYTHON DATAFRAME\"\"\"\n",
    "vst_frame = pd.DataFrame(v)\n",
    "vst_frame.columns = deseq_data.columns\n",
    "vst_frame.index = deseq_data.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLUSTERING VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"PCA PLOTS\"\"\"\n",
    "\"\"\"PCA with dataFrames from list.  Loadings can be returned for the last datframe in the list to get the most important\n",
    "genes.  Not sure how usefull this may prove, so leaving it basic for now.\"\"\"\n",
    "def run_pca(data_frame_list, color):\n",
    "    loading_dict = {}\n",
    "    ix = 0\n",
    "    for df in data_frame_list:\n",
    "        \"\"\"Getting the indexes for each pca frame\"\"\"\n",
    "        indicies = df.columns.tolist()\n",
    "        \n",
    "        pca = PCA(n_components=5)\n",
    "        pca.fit(df.T)\n",
    "        variance = pca.explained_variance_ratio_\n",
    "        pca_frame = pd.DataFrame(pca.fit_transform(df.T))\n",
    "        pca_frame.index = indicies\n",
    "        \n",
    "        pca_frame = pca_frame.merge(metadata[['batch', 'type', 'cond_1', 'cond_2']], left_index=True, \n",
    "                                    right_index=True, how='left')\n",
    "        \n",
    "        pca_frame.columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5',\n",
    "                             'batch', 'type', 'cond_1', 'cond_2']\n",
    "\n",
    "\n",
    "        sns.set(style='darkgrid', context='talk')\n",
    "        fig, ax = plt.subplots(figsize=(20, 15))\n",
    "        g = sns.scatterplot(x=pca_frame['PC1'], y=pca_frame['PC2'], hue=pca_frame[color], s=200)\n",
    "        g.legend(loc='center left', bbox_to_anchor=(1., 0.5), ncol=1)\n",
    "        g.set_title(\"PCA\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(variance)\n",
    "        loadings = pd.DataFrame(np.abs(pca.components_.T))\n",
    "        loadings.index = df.index.copy()\n",
    "        loading_dict[ix] = loadings\n",
    "        ix += 1\n",
    "#         return loading_dict\n",
    "    \n",
    "\"\"\"For all samples\"\"\"\n",
    "run_pca([deseq_data, norm_filtered, quant_normed], 'batch')    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"MDS PLOTS\"\"\"\n",
    "def run_mds(dataframe_list, color, metadata):\n",
    "    for df in dataframe_list:\n",
    "        \"\"\"Getting indicies\"\"\"\n",
    "        indicies = df.columns.tolist()\n",
    "        \n",
    "        all_bc_dm = beta_diversity('braycurtis', (df.T + 1).astype('int64').values)\n",
    "        pco_all = pcoa(all_bc_dm)\n",
    "        pco_df = pco_all.samples\n",
    "        var_exp = pco_all.proportion_explained\n",
    "        plot_data = pco_all.samples.iloc[:, [0,1]]\n",
    "        plot_data = plot_data.div(plot_data.abs().max(axis=0), axis=1)\n",
    "        \n",
    "        \"\"\"Merging in transposed df metadata\"\"\"\n",
    "        plot_data.index = indicies\n",
    "        plot_data = plot_data.merge(metadata[['batch', 'type', 'cond_1', 'cond_2', ]], \n",
    "                                    left_index=True, right_index=True, how='left')\n",
    "        \n",
    "        \n",
    "        sns.set(style='darkgrid', context='talk')\n",
    "        fig, ax = plt.subplots(figsize=(20, 15))\n",
    "        g = sns.scatterplot(x=plot_data['PC1'], y=plot_data['PC2'], hue=plot_data[color], s=200)\n",
    "        g.set_xlabel(str('PC1 ' + str(np.round(var_exp[0] * 100, 1)) + '%'))\n",
    "        g.set_ylabel(str('PC2 ' + str(np.round(var_exp[1] * 100, 1)) + '%'))\n",
    "        g.legend(loc='center left', bbox_to_anchor=(1., 0.5), ncol=1)\n",
    "        g.set_title(\"PCO\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "\"\"\"Run for all samples\"\"\"\n",
    "run_mds([deseq_data, norm_filtered, quant_filtered, ], 'batch', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"TSNE PLOTS\"\"\"\n",
    "def run_tsne(dataframe_list, color):\n",
    "    for df in dataframe_list:\n",
    "        tsne = TSNE(n_components=2, verbose=1, perplexity=5, n_iter=5000)\n",
    "        tsne_results = tsne.fit_transform(df.T)\n",
    "        tsne_plotting = pd.DataFrame(tsne_results, columns=['Component_1', 'Component_2'])\n",
    "        tsne_plotting.index = df.T.index\n",
    "        tsne_plotting = tsne_plotting.merge(metadata[['batch', 'type', 'cond_1', 'cond_2']], left_index=True, \n",
    "                                            right_index=True, how='left')\n",
    "        \n",
    "        sns.set(style='darkgrid', context='talk')\n",
    "        fig, ax = plt.subplots(figsize=(20, 15))\n",
    "        g = sns.scatterplot(x=tsne_plotting['Component_1'], y=tsne_plotting['Component_2'], hue=tsne_plotting[color], s=200)\n",
    "        g.legend(loc='center left', bbox_to_anchor=(1., 0.5), ncol=1)\n",
    "        g.set_title(\"TSNE\")\n",
    "        #     g.set(ylim=(-1.2, 1.2), xlim=(-1.2, 1.2))\n",
    "        plt.tight_layout()\n",
    "        \n",
    "\"\"\"Run for all samples\"\"\"\n",
    "run_tsne([deseq_data, norm_filtered, vst_frame], 'batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"HEATMAPS\"\"\"\n",
    "def run_heirarchical(dataframe_list):\n",
    "    from matplotlib.colors import LogNorm\n",
    "    import math\n",
    "    for df in dataframe_list:\n",
    "        cmap = sns.cm.rocket_r\n",
    "#         cmap = sns.diverging_palette(200, 20, as_cmap=True)\n",
    "        heat_map_data = df.copy()\n",
    "        heat_map_data[heat_map_data < 1] = 1\n",
    "        log_norm = LogNorm(vmin=heat_map_data.min().min(), vmax=heat_map_data.max().max())\n",
    "        cbar_ticks = [math.pow(10, i) for i in range(math.floor(math.log10(heat_map_data.min().min())), \n",
    "                                                     1+math.ceil(math.log10(heat_map_data.max().max())))]\n",
    "        \"\"\"Either one of these works, so maybe can introduce another column to merge in the gene names\"\"\"\n",
    "        g = sns.clustermap(heat_map_data, metric='braycurtis', norm=log_norm, cmap=\"RdBu_r\", cbar_kws={\"ticks\": cbar_ticks}, \n",
    "                           xticklabels=True, yticklabels=0, figsize=(14,10))\n",
    "        # g = sns.clustermap(heat_map_data,\n",
    "        #                    norm=log_norm, cmap=cmap, vmin=1E6, cbar_kws={\"ticks\": cbar_ticks}, yticklabels=1, figsize=(14,10))\n",
    "\n",
    "        g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_yticklabels(), fontsize=0)\n",
    "        g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), fontsize=10)\n",
    "        g.ax_row_dendrogram.set_visible(False)\n",
    "        g.cax.set_position([.10, .59, .03, .25])\n",
    "    \n",
    "\"\"\"Run for all samples\"\"\"    \n",
    "run_heirarchical([deseq_data, norm_filtered, quant_filtered])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"HEATMAPS ZSCORE\"\"\"\n",
    "def run_heirarchical(dataframe_list):\n",
    "    from matplotlib.colors import LogNorm\n",
    "    import math\n",
    "    for df in dataframe_list:\n",
    "        cmap = sns.cm.rocket_r\n",
    "        heat_map_data = df.copy()\n",
    "        heat_map_data[heat_map_data < 1] = 1\n",
    "        \"\"\"Either one of these works, so maybe can introduce another column to merge in the gene names\"\"\"\n",
    "        g = sns.clustermap(heat_map_data, z_score=0, cmap=\"RdBu_r\", \n",
    "                           xticklabels=True, yticklabels=0,  col_cluster=True, row_cluster=True, figsize=(14,10))\n",
    "        # g = sns.clustermap(heat_map_data,\n",
    "        #                    norm=log_norm, cmap=cmap, vmin=1E6, cbar_kws={\"ticks\": cbar_ticks}, yticklabels=1, figsize=(14,10))\n",
    "\n",
    "        g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_yticklabels(), fontsize=0)\n",
    "        g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), fontsize=10)\n",
    "        g.ax_row_dendrogram.set_visible(False)\n",
    "        g.cax.set_position([.10, .59, .03, .25])\n",
    "    \n",
    "\"\"\"Run for all samples\"\"\"    \n",
    "run_heirarchical([norm_filtered])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIFFERENTIAL EXPRESSION TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Runs DESeq of all groups vs all groups comparisions, yielding dictionary of dataframes containing DESeq results for each possible comparison\n",
    "within the set of comparators \"\"\"\n",
    "\n",
    "def get_deseq_comparison(dds, contrast_list, variable, transposed_df):\n",
    "    \"\"\"Import and Helper functions\"\"\"\n",
    "    from rpy2 import robjects\n",
    "    from rpy2.robjects.packages import importr\n",
    "    deseq = importr('DESeq2')\n",
    "    to_dataframe = robjects.r('function(x) data.frame(x)')\n",
    "    \n",
    "    \"\"\"Does all vs all comparisons through the list iteration method\n",
    "    Introducing this so that the foldchange frames can be more easily matched up with the \n",
    "    appropriate sample data\"\"\"\n",
    "    fold_change_dict = {}\n",
    "    for i in range(len(contrast_list)):\n",
    "        j = i\n",
    "        while j + 1 < len(contrast_list):\n",
    "            \"\"\"Getting DESeq results\"\"\"\n",
    "            contrast_name = str(contrast_list[i] + '_v_' + contrast_list[j+1])\n",
    "            contrast_array = np.asarray([variable, contrast_list[i], contrast_list[j+1]])\n",
    "            res = deseq.results(dds, contrast = contrast_array)\n",
    "            \n",
    "            \"\"\"Merging with mean values for appropriate comparisons\"\"\"\n",
    "            pre_pivot = transposed_df[transposed_df['process'].isin([contrast_list[i], contrast_list[j+1]])].copy()\n",
    "            pre_pivot.drop(['batch', 'cond_1', 'cond_2', 'cond_3', 'type'], \n",
    "                           axis=1, inplace=True)\n",
    "            pivoted = pre_pivot.pivot_table(index='process', aggfunc='mean').T\n",
    "            pivoted['read_max'] = pivoted.max(axis=1)\n",
    "            \"\"\"Turn R df into pandas and merge with values from pivoted\"\"\"\n",
    "            fold_change_dict[contrast_name] = to_dataframe(res).merge(pivoted, left_index=True, right_index=True,\n",
    "                                                                     how='left')\n",
    "\n",
    "            \n",
    "            j+=1\n",
    "    return fold_change_dict, pivoted\n",
    "fold_change_dict, pivoted = get_deseq_comparison(dds, ['cond_1', 'cond_2', 'cond_3'], 'process', transposed)\n",
    " \"\"\"For saving fc dict to file\"\"\"\n",
    "for key in fold_change_dict:\n",
    "    fold_change_dict[key].to_csv(data_dir + '/process_' + key + '_fc.csv')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"MAKING FOLD CHANGE PLOTS FOR ALL USER DEFINED COMPARISONS\"\"\"\n",
    "def volcano_plots(fold_change_dict):\n",
    "    keys = fold_change_dict.keys()\n",
    "    for key in keys:\n",
    "        plotting_frame = fold_change_dict[key].copy()\n",
    "        plotting_frame = plotting_frame[plotting_frame['read_max'] > 5]\n",
    "#         print(plotting_frame)\n",
    "        plotting_frame['sig'] = 0\n",
    "#         plotting_frame['sig'] = np.where(plotting_frame['padj'] > 0.05, 0, 1)\n",
    "        plotting_frame['sig'] = np.where((np.abs(plotting_frame['log2FoldChange']) > 1) & (plotting_frame['padj'] < 0.05), \n",
    "                                         1, 0)\n",
    "#         print(plotting_frame)\n",
    "        sns.set(style='darkgrid', context='talk')\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        g = sns.scatterplot(x=plotting_frame['log2FoldChange'], y=-np.log10(plotting_frame['padj']), \n",
    "                            hue=plotting_frame['sig'],legend=False, s=50, style=plotting_frame['sig'], \n",
    "                            markers=[\"o\", \"o\"])\n",
    "#         palette=['black','red']\n",
    "#         g.legend(loc='center left', bbox_to_anchor=(1., 0.5), ncol=1)\n",
    "        g.set_ylabel('-log10 P-Value')\n",
    "        g.set_xlabel('log2 Fold Change')\n",
    "        g.set_title(key)\n",
    "        g.set(ylim=(-0.5, 20), xlim=(-7, 7))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(data_dir + '/process_' + key + '_volcano_min5.png')\n",
    "\n",
    "\n",
    "volcano_plots(fold_change_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Annotate Differentially expressed proteins\"\"\"\n",
    "def annotated_diff(fold_change_dict, annotations, read_thresh):\n",
    "    keys = fold_change_dict.keys()\n",
    "    sig_annot_dict = {}\n",
    "    for key in keys:\n",
    "        plotting_frame = fold_change_dict[key].copy()\n",
    "#         print(plotting_frame)\n",
    "        plotting_frame['sig'] = 0\n",
    "#         plotting_frame['sig'] = np.where(plotting_frame['padj'] > 0.05, 0, 1)\n",
    "        plotting_frame['sig'] = np.where((np.abs(plotting_frame['log2FoldChange']) > 1) & (plotting_frame['padj'] < 0.05) & \n",
    "                                         (plotting_frame['read_max'] > read_thresh), 1, 0)\n",
    "        diff_frame = plotting_frame.copy()\n",
    "        \n",
    "        annotated_diff = diff_frame.merge(annotations[['locus_tag', 'name', 'uniprot_kwds', 'go_kwds']], \n",
    "                                       left_index=True, right_on='locus_tag', how='left')\n",
    "        annotated_diff.sort_values(by='read_max', ascending=False, inplace=True)\n",
    "        annotated_diff = annotated_diff[annotated_diff['sig'] == 1]\n",
    "        annotated_diff.drop_duplicates(subset='locus_tag', keep='first', inplace=True)\n",
    "        sig_annot_dict[key] = annotated_diff.drop(['baseMean', 'lfcSE', 'stat', 'pvalue',\n",
    "                                                  'sig'], axis=1)\n",
    "        \n",
    "    return sig_annot_dict\n",
    "\n",
    "sig_annotated_dict = annotated_diff(fold_change_dict, genome_annotations, 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
